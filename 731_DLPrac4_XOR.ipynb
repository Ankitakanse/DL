{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e581c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential# supervised\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53baa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=2,input_dim=2,activation='relu')) \n",
    "model.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb353ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[array([[ 0.6077728 , -0.21834826],\n",
      "       [-0.03964341,  0.65608716]], dtype=float32), array([0., 0.], dtype=float32), array([[ 0.9690279],\n",
      "       [-1.1592028]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')\n",
    "print(model.summary())\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72f9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "X=np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac87f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array([0.,1.,1.,0.])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ea7ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7060 - accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7057 - accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7053 - accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7050 - accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7046 - accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7039 - accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7036 - accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7029 - accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7026 - accuracy: 0.5000\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.5000\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7019 - accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7016 - accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7012 - accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7005 - accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7002 - accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6999 - accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6995 - accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6992 - accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6988 - accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6978 - accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6968 - accuracy: 0.5000\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6958 - accuracy: 0.5000\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.5000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6888 - accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6885 - accuracy: 0.5000\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.5000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.5000\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.5000\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5000\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5000\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5000\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6852 - accuracy: 0.5000\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6845 - accuracy: 0.5000\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6842 - accuracy: 0.5000\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6839 - accuracy: 0.5000\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.5000\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6822 - accuracy: 0.5000\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5000\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5000\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.5000\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5000\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6802 - accuracy: 0.5000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6799 - accuracy: 0.5000\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.5000\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.5000\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5000\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6786 - accuracy: 0.5000\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5000\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6779 - accuracy: 0.5000\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5000\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.5000\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.5000\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5000\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.5000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.5000\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6756 - accuracy: 0.5000\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6753 - accuracy: 0.5000\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6750 - accuracy: 0.5000\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6747 - accuracy: 0.5000\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6743 - accuracy: 0.5000\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.5000\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.5000\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6734 - accuracy: 0.5000\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5000\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.5000\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.5000\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5000\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5000\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.5000\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6711 - accuracy: 0.5000\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6707 - accuracy: 0.5000\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.5000\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6701 - accuracy: 0.5000\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.5000\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6694 - accuracy: 0.5000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6691 - accuracy: 0.5000\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.5000\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6685 - accuracy: 0.5000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6681 - accuracy: 0.5000\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6678 - accuracy: 0.5000\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6675 - accuracy: 0.5000\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6671 - accuracy: 0.5000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6668 - accuracy: 0.5000\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.5000\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6662 - accuracy: 0.5000\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6658 - accuracy: 0.5000\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6655 - accuracy: 0.5000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6652 - accuracy: 0.5000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.5000\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6646 - accuracy: 0.5000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6644 - accuracy: 0.5000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6641 - accuracy: 0.5000\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.5000\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6634 - accuracy: 0.5000\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6632 - accuracy: 0.5000\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6629 - accuracy: 0.5000\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6626 - accuracy: 0.5000\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6623 - accuracy: 0.5000\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6620 - accuracy: 0.5000\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6612 - accuracy: 0.5000\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6609 - accuracy: 0.5000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6606 - accuracy: 0.5000\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.5000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6600 - accuracy: 0.5000\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6598 - accuracy: 0.5000\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6595 - accuracy: 0.5000\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.5000\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6589 - accuracy: 0.5000\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6586 - accuracy: 0.5000\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6583 - accuracy: 0.5000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6580 - accuracy: 0.5000\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6577 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2027f448130>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=150,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636c101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.5166231 , -0.12055355],\n",
      "       [-0.13766275,  0.5632488 ]], dtype=float32), array([-0.09114985, -0.09283857], dtype=float32), array([[ 0.92149335],\n",
      "       [-1.0699748 ]], dtype=float32), array([0.05433995], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc1f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.51358163],\n",
       "       [0.38960162],\n",
       "       [0.60978544],\n",
       "       [0.4863078 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e0edc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if y_pred.all() > 0.5:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdba7993",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvec2scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m, in \u001b[0;36mvec2scalar\u001b[1;34m(list_)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m      6\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0.8\u001b[39m:\n\u001b[0;32m      8\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(vec2scalar(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b5ba59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(vec2scalar(\u001b[43my_test\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(vec2scalar(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c87a3d",
   "metadata": {},
   "source": [
    "# Perform multiclass classification on the wine data set using deep feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e5abbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51458226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= load_wine()\n",
    "x = pd.DataFrame(data.data,columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target,columns = ['Target'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c052b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "173       2\n",
       "174       2\n",
       "175       2\n",
       "176       2\n",
       "177       2\n",
       "\n",
       "[178 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bf64115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "encoded_Y=np_utils.to_categorical(y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d11c19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=13,activation='relu')) \n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7290778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cc01a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 312.1954 - accuracy: 0.2697\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 238.6547 - accuracy: 0.2697\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 179.7201 - accuracy: 0.2697\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 137.0419 - accuracy: 0.2697\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 103.2876 - accuracy: 0.2697\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 78.4082 - accuracy: 0.2697\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 58.2779 - accuracy: 0.2697\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 44.1005 - accuracy: 0.2697\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 32.1683 - accuracy: 0.2697\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.6548 - accuracy: 0.2697\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 17.3413 - accuracy: 0.2697\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.9426 - accuracy: 0.2865\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.6039 - accuracy: 0.2978\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.4563 - accuracy: 0.2809\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7494 - accuracy: 0.2697\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.0452 - accuracy: 0.2753\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5907 - accuracy: 0.2753\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.5736 - accuracy: 0.2640\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.2528\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.5730\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8418 - accuracy: 0.6180\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8257 - accuracy: 0.6348\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7993 - accuracy: 0.6236\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7889 - accuracy: 0.6124\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.6180\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7666 - accuracy: 0.6180\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7541 - accuracy: 0.6180\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7526 - accuracy: 0.6067\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.6461\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7336 - accuracy: 0.6348\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.6348\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.6461\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7175 - accuracy: 0.6461\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.6292\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6685\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.6517\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6742\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.6348\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.6180\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6854\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6685\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6910\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6966\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7022\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6854\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6966\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7022\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.7135\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.7022\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.7135\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.7079\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7360\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7416\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.7135\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.7079\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.7416\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.7360\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.7247\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.7472\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7247\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.7303\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7584\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7247\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.7584\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6966\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7472\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.7640\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.7584\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.7472\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.5874 - accuracy: 0.7472\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5767 - accuracy: 0.7753\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7640\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7528\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.7528\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7528\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7697\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7809\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7697\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7360\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.8034\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7472\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7978\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.8034\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7809\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7921\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7978\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7865\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.5277 - accuracy: 0.7978\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.8034\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7584\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.8202\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.8315\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7978\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8258\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7921\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8539\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8371\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.8371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202066879a0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,encoded_Y,epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c146ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "043d2eb5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.99771774e-01, 6.59248644e-06, 2.21650029e-04],\n",
       "       [9.99999285e-01, 1.85795912e-09, 7.45046520e-07],\n",
       "       [1.00000000e+00, 1.06638077e-14, 1.66098801e-10],\n",
       "       [1.15550108e-01, 5.51880240e-01, 3.32569599e-01],\n",
       "       [1.00000000e+00, 3.74592189e-14, 3.98613725e-10],\n",
       "       [1.00000000e+00, 2.73459776e-13, 1.59254165e-09],\n",
       "       [9.99991655e-01, 5.93203815e-08, 8.32202932e-06],\n",
       "       [9.99829412e-01, 4.35968832e-06, 1.66165715e-04],\n",
       "       [9.99729455e-01, 8.39147560e-06, 2.62225891e-04],\n",
       "       [1.00000000e+00, 1.14332929e-17, 1.41632843e-12],\n",
       "       [1.00000000e+00, 3.26633685e-13, 1.80243276e-09],\n",
       "       [1.00000000e+00, 1.07225424e-15, 3.35171717e-11],\n",
       "       [9.99999881e-01, 1.90100033e-10, 1.52177762e-07],\n",
       "       [1.00000000e+00, 4.02594310e-19, 1.37580553e-13],\n",
       "       [9.99999762e-01, 4.03989897e-10, 2.57314156e-07],\n",
       "       [9.99984384e-01, 1.44410635e-07, 1.54686986e-05],\n",
       "       [9.97482121e-01, 1.92567692e-04, 2.32538208e-03],\n",
       "       [1.00000000e+00, 2.48767158e-21, 3.97517856e-15],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.23560414e-01, 5.45540631e-01, 3.30899000e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.99412894e-01, 2.50669218e-05, 5.62054513e-04],\n",
       "       [9.99824822e-01, 4.53104713e-06, 1.70689309e-04],\n",
       "       [4.78121042e-01, 2.51014590e-01, 2.70864308e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.00000000e+00, 2.23640308e-11, 3.42577202e-08],\n",
       "       [1.00000000e+00, 7.74254589e-14, 6.61087740e-10],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.99866486e-01, 3.07948494e-06, 1.30422079e-04],\n",
       "       [1.00000000e+00, 4.40325163e-12, 1.10407754e-08],\n",
       "       [1.00000000e+00, 2.09876120e-17, 2.16254055e-12],\n",
       "       [9.83805776e-01, 2.47466518e-03, 1.37195215e-02],\n",
       "       [9.92653131e-01, 8.44234019e-04, 6.50268421e-03],\n",
       "       [9.98697519e-01, 7.67735037e-05, 1.22570980e-03],\n",
       "       [8.83527040e-01, 3.40170488e-02, 8.24559554e-02],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.99989152e-01, 8.58110951e-08, 1.07633596e-05],\n",
       "       [9.99595702e-01, 1.48104973e-05, 3.89556546e-04],\n",
       "       [9.58807319e-02, 5.65028369e-01, 3.39090824e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.99988794e-01, 8.95021159e-08, 1.10838600e-05],\n",
       "       [9.99940038e-01, 9.85426368e-07, 5.89610208e-05],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.95885074e-01, 3.80341924e-04, 3.73456371e-03],\n",
       "       [9.99752104e-01, 7.41233816e-06, 2.40510592e-04],\n",
       "       [9.90449607e-01, 1.20823528e-03, 8.34215153e-03],\n",
       "       [9.99288142e-01, 3.28838942e-05, 6.79043937e-04],\n",
       "       [9.99999285e-01, 1.59865166e-09, 6.70960617e-07],\n",
       "       [9.99999881e-01, 2.38713244e-10, 1.78343114e-07],\n",
       "       [1.00000000e+00, 4.30088745e-13, 2.18333285e-09],\n",
       "       [9.99966383e-01, 4.30347995e-07, 3.31032497e-05],\n",
       "       [1.00000000e+00, 2.05428712e-11, 3.22890727e-08],\n",
       "       [8.46992850e-01, 4.86109667e-02, 1.04396231e-01],\n",
       "       [9.95763063e-01, 3.96008778e-04, 3.84094752e-03],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.00000000e+00, 2.02241904e-11, 3.19392583e-08],\n",
       "       [9.99999881e-01, 2.05554601e-10, 1.60695123e-07],\n",
       "       [1.03854537e-01, 5.59676409e-01, 3.36469054e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [5.56252431e-04, 6.68466449e-01, 3.30977380e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.14438199e-02, 6.36561036e-01, 3.51995170e-01],\n",
       "       [3.36537305e-05, 6.49219334e-01, 3.50746989e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [6.17698170e-05, 6.53952956e-01, 3.45985234e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.05638765e-02, 6.37809753e-01, 3.51626337e-01],\n",
       "       [2.53153890e-02, 6.20883524e-01, 3.53801161e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [6.25624001e-01, 1.57931596e-01, 2.16444433e-01],\n",
       "       [8.10830505e-04, 6.65706754e-01, 3.33482504e-01],\n",
       "       [3.13143339e-03, 6.52918875e-01, 3.43949735e-01],\n",
       "       [5.77781757e-04, 6.68546557e-01, 3.30875665e-01],\n",
       "       [2.29354785e-03, 6.56079650e-01, 3.41626883e-01],\n",
       "       [4.26654471e-03, 6.49573803e-01, 3.46159607e-01],\n",
       "       [2.92279903e-04, 6.65825188e-01, 3.33882600e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [7.66617134e-02, 5.78891158e-01, 3.44447166e-01],\n",
       "       [2.42048502e-02, 6.21976852e-01, 3.53818297e-01],\n",
       "       [2.29431246e-03, 6.56076193e-01, 3.41629505e-01],\n",
       "       [1.91076118e-02, 6.27261162e-01, 3.53631198e-01],\n",
       "       [2.01160267e-01, 4.44648176e-01, 3.54191542e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [3.88889939e-01, 3.15761119e-01, 2.95348942e-01],\n",
       "       [8.33072588e-02, 5.74003458e-01, 3.42689246e-01],\n",
       "       [8.56205262e-03, 6.40889704e-01, 3.50548238e-01],\n",
       "       [1.01657316e-01, 5.61147928e-01, 3.37194711e-01],\n",
       "       [4.48630744e-04, 6.68002546e-01, 3.31548810e-01],\n",
       "       [1.98887356e-04, 6.62927866e-01, 3.36873293e-01],\n",
       "       [3.41105834e-03, 6.52016938e-01, 3.44572037e-01],\n",
       "       [8.77650673e-05, 6.56670868e-01, 3.43241334e-01],\n",
       "       [2.21557058e-02, 6.24043941e-01, 3.53800476e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.03288097e-02, 6.38153017e-01, 3.51518124e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [3.09860334e-03, 6.53028846e-01, 3.43872547e-01],\n",
       "       [1.05361547e-02, 6.37850046e-01, 3.51613760e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [3.63619998e-04, 6.67450964e-01, 3.32185388e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [4.60701324e-02, 6.02556884e-01, 3.51372987e-01],\n",
       "       [1.98403854e-04, 6.62909389e-01, 3.36892128e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.20039573e-02, 6.35792851e-01, 3.52203190e-01],\n",
       "       [1.08718779e-03, 6.63095236e-01, 3.35817516e-01],\n",
       "       [3.92851643e-02, 6.08225346e-01, 3.52489471e-01],\n",
       "       [5.93911251e-03, 6.45691276e-01, 3.48369598e-01],\n",
       "       [8.25562421e-03, 6.41397476e-01, 3.50346923e-01],\n",
       "       [8.35888926e-03, 6.41225100e-01, 3.50416034e-01],\n",
       "       [8.47144127e-02, 5.72976589e-01, 3.42308998e-01],\n",
       "       [2.00387003e-05, 6.45148218e-01, 3.54831696e-01],\n",
       "       [9.87000670e-03, 6.38835788e-01, 3.51294160e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [7.10061358e-05, 6.55033171e-01, 3.44895810e-01],\n",
       "       [1.76101486e-04, 6.62005007e-01, 3.37818921e-01],\n",
       "       [1.41931996e-02, 6.32955194e-01, 3.52851540e-01],\n",
       "       [2.04711165e-02, 6.25798404e-01, 3.53730470e-01],\n",
       "       [8.48374330e-03, 6.41018391e-01, 3.50497872e-01],\n",
       "       [2.13049096e-03, 6.56803727e-01, 3.41065764e-01],\n",
       "       [5.78857400e-03, 6.46006346e-01, 3.48205060e-01],\n",
       "       [8.95672361e-04, 6.64827585e-01, 3.34276855e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [8.01262970e-04, 6.65811241e-01, 3.33387434e-01],\n",
       "       [1.59622100e-03, 6.59565866e-01, 3.38837981e-01],\n",
       "       [6.67983387e-03, 6.44215167e-01, 3.49105030e-01],\n",
       "       [8.55259690e-03, 6.40905201e-01, 3.50542247e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [7.57642416e-03, 6.42566025e-01, 3.49857599e-01],\n",
       "       [1.96188748e-01, 4.50366765e-01, 3.53444487e-01],\n",
       "       [2.29303129e-02, 6.23254418e-01, 3.53815317e-01],\n",
       "       [7.31117427e-02, 5.81530094e-01, 3.45358163e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [7.61156483e-03, 6.42503977e-01, 3.49884450e-01],\n",
       "       [8.76500905e-02, 5.70842505e-01, 3.41507435e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.15660364e-02, 6.36391759e-01, 3.52042258e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.95944798e-04, 6.62814915e-01, 3.36989194e-01],\n",
       "       [6.33740592e-06, 6.36024833e-01, 3.63968819e-01],\n",
       "       [1.76808007e-05, 6.44161463e-01, 3.55820864e-01],\n",
       "       [3.75935929e-06, 6.31851852e-01, 3.68144393e-01],\n",
       "       [7.60282576e-02, 5.79360545e-01, 3.44611257e-01],\n",
       "       [1.34253772e-02, 6.33923590e-01, 3.52651000e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [4.87966975e-03, 6.48041308e-01, 3.47079068e-01],\n",
       "       [5.62029541e-01, 1.96065426e-01, 2.41905063e-01],\n",
       "       [2.58133095e-02, 6.20398760e-01, 3.53787929e-01],\n",
       "       [6.04868643e-02, 5.91109097e-01, 3.48404080e-01],\n",
       "       [2.41240039e-02, 6.22057080e-01, 3.53818864e-01],\n",
       "       [6.30818829e-02, 5.89112103e-01, 3.47805977e-01],\n",
       "       [3.78478994e-03, 6.50897801e-01, 3.45317423e-01],\n",
       "       [6.69401661e-02, 5.86171448e-01, 3.46888393e-01],\n",
       "       [7.40531459e-02, 5.80828249e-01, 3.45118612e-01],\n",
       "       [2.40492001e-02, 6.22131526e-01, 3.53819311e-01],\n",
       "       [9.00539756e-03, 6.40174091e-01, 3.50820601e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [1.51201829e-01, 5.06343067e-01, 3.42455059e-01],\n",
       "       [3.35446093e-03, 6.52194619e-01, 3.44450980e-01],\n",
       "       [4.25272202e-03, 6.49610281e-01, 3.46136957e-01],\n",
       "       [3.16022290e-03, 6.52823091e-01, 3.44016671e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [2.01432392e-01, 4.44337457e-01, 3.54230106e-01],\n",
       "       [9.32682008e-02, 5.66789329e-01, 3.39942425e-01],\n",
       "       [9.66598764e-02, 5.64503968e-01, 3.38836133e-01],\n",
       "       [8.83709081e-03, 6.40443146e-01, 3.50719810e-01]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87223414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
